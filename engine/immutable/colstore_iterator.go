// Copyright 2025 Huawei Cloud Computing Technologies Co., Ltd.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package immutable

import (
	"bytes"
	"errors"
	"io"
	"math"
	"sort"

	"github.com/openGemini/openGemini/engine/immutable/colstore"
	"github.com/openGemini/openGemini/lib/errno"
	"github.com/openGemini/openGemini/lib/fileops"
	"github.com/openGemini/openGemini/lib/fragment"
	"github.com/openGemini/openGemini/lib/logger"
	"github.com/openGemini/openGemini/lib/record"
)

type CSIteratorCursor struct {
	ranges      []fragment.FragmentRange
	fragmentIdx int
	segmentIdx  int
}

func (c *CSIteratorCursor) Init(fragments []int64) {
	c.fragmentIdx = 0
	c.segmentIdx = 0
	c.ranges = make([]fragment.FragmentRange, len(fragments))

	var start uint32 = 0
	for i, v := range fragments {
		c.ranges[i].Start = start
		c.ranges[i].End = uint32(v)
		start = uint32(v)
	}
}

func (c *CSIteratorCursor) NextFragment() (int, bool) {
	if c.fragmentIdx >= len(c.ranges) {
		return 0, false
	}
	c.fragmentIdx++
	c.segmentIdx = 0
	return c.fragmentIdx - 1, true
}

func (c *CSIteratorCursor) NextSegment() (int, bool) {
	if c.fragmentIdx == 0 {
		return 0, false
	}
	fr := c.ranges[c.fragmentIdx-1]

	if c.segmentIdx >= fr.NumberOfSegments() {
		return 0, false
	}

	c.segmentIdx++
	return int(fr.Start) + c.segmentIdx - 1, true
}

type CSFileIterator struct {
	file       TSSPFile
	skSchema   record.Schemas
	tcDuration int64

	pkCols   []*record.ColVal
	pkSchema record.Schemas
	ctx      *ReadContext
	cm       *ChunkMeta

	segment   *record.Record
	remainRow int
	pk        []byte
	ncs       record.NilCounts

	cursor CSIteratorCursor
}

func NewCSFileIterator(file TSSPFile, skSchema record.Schemas, tcDuration int64) (*CSFileIterator, error) {
	ci := &CSFileIterator{
		file:       file,
		skSchema:   skSchema,
		tcDuration: tcDuration,
		ctx:        NewReadContext(true),
	}

	if err := ci.initPKInfo(); err != nil {
		return nil, err
	}

	err := ci.initSchema()
	return ci, err
}

func (ci *CSFileIterator) initPKInfo() error {
	pki := ci.file.GetPkInfo()
	rec := pki.GetRec()

	schema := rec.Schema
	last := schema.Field(schema.Len() - 1)
	if last == nil || last.Name != record.FragmentField {
		return errors.New("invalid primary key record schema")
	}

	schema = schema[:schema.Len()-1]
	ci.pkCols = record.FetchColVals(rec, schema)
	ci.pkSchema = schema
	fragments := rec.ColVals[rec.Len()-1].IntegerValues()
	ci.cursor.Init(fragments)

	return nil
}

func (ci *CSFileIterator) initSchema() error {
	fi := NewFileIterator(ci.file, logger.NewLogger(errno.ModuleCompact))
	ok := fi.NextChunkMeta()
	ci.cm = fi.GetCurtChunkMeta()
	if !ok || ci.cm == nil {
		return errors.New("invalid chunk meta")
	}

	columns := ci.cm.GetColMeta()

	schema := make(record.Schemas, len(columns))
	for i := range columns {
		schema[i].Type = int(columns[i].Type())
		schema[i].Name = columns[i].Name()
	}
	ci.segment = &record.Record{}
	ci.segment.ResetWithSchema(schema)
	return nil
}

func (ci *CSFileIterator) NextFragment() bool {
	if ci.remainRow > 0 {
		return true
	}
	i, ok := ci.cursor.NextFragment()
	if !ok {
		return false
	}
	ci.pk = colstore.FetchKeyAtRow(ci.pk[:0], ci.pkCols, ci.pkSchema, i, ci.tcDuration)
	return true
}

func (ci *CSFileIterator) NextSegment() error {
	i, ok := ci.cursor.NextSegment()
	if !ok {
		return io.EOF
	}

	rec, err := ci.file.ReadAt(ci.cm, i, ci.segment, ci.ctx, fileops.IO_PRIORITY_LOW)
	if err != nil {
		return err
	}

	ci.segment = rec
	ci.remainRow = rec.RowNums()
	ci.ncs.Build(rec)
	return nil
}

func (ci *CSFileIterator) ReadAll() *record.Record {
	ci.remainRow = 0
	return ci.segment
}

func (ci *CSFileIterator) ReadFragmentPK() map[string]any {
	idx := ci.cursor.fragmentIdx - 1
	if idx < 0 {
		return nil
	}

	pk := make(map[string]any)
	for i := range ci.pkSchema {
		name := ci.pkSchema[i].Name
		pk[name] = record.ReadRowValue(ci.pkCols[i], ci.pkSchema[i].Type, idx)
	}

	return pk
}

func (ci *CSFileIterator) AppendRecordRowTo(dst *record.Record, rowIdx int) {
	i, j := 0, 0
	n := dst.Len() - 1
	m := ci.segment.Len() - 1

	for i < n && j < ci.segment.Len()-1 {
		si := &dst.Schema[i]
		sj := &ci.segment.Schema[j]

		if si.Name == sj.Name {
			dst.ColVals[i].AppendWithNilCount(&ci.segment.ColVals[j], sj.Type, rowIdx, rowIdx+1, ci.ncs.Column(j))
			i++
			j++
		} else if si.Name < sj.Name {
			dst.ColVals[i].PadColVal(si.Type, 1)
			i++
		}
	}

	for ; i < n; i++ {
		dst.ColVals[i].PadColVal(dst.Schema[i].Type, 1)
	}

	// time column
	dst.ColVals[n].AppendColVal(&ci.segment.ColVals[m], dst.Schema[n].Type, rowIdx, rowIdx+1)

	ci.remainRow--
}

func (ci *CSFileIterator) RemainRecordRow() int {
	return ci.remainRow
}

func (ci *CSFileIterator) SegmentRecord() *record.Record {
	return ci.segment
}

type FragmentIteratorBuilder struct {
	colstore.KeySorter
	its []*CSFileIterator
	fi  *FragmentIterator
}

func NewFragmentIteratorBuilder(its []*CSFileIterator, skSchema record.Schemas) *FragmentIteratorBuilder {
	fi := NewFragmentIterator(skSchema)
	fi.BuildCompactedSchema(its)
	return &FragmentIteratorBuilder{
		its: its,
		fi:  fi,
	}
}

func (b *FragmentIteratorBuilder) Swap(i, j int) {
	b.KeySorter.Swap(i, j)
	b.its[i], b.its[j] = b.its[j], b.its[i]
}

func (b *FragmentIteratorBuilder) BuildNext() (*FragmentIterator, []byte, error) {
	b.nextFragment()
	if len(b.its) == 0 {
		return nil, nil, io.EOF
	}

	err := b.nextSegment()
	if err != nil {
		return nil, nil, err
	}

	fi := b.fi
	fi.Reset()

	var pk []byte
	for i, it := range b.its {
		if i > 0 && !bytes.Equal(it.pk, pk) {
			break
		}

		pk = it.pk
		fi.AddCSFileIterator(it)
	}

	sort.Sort(fi)
	return fi, pk, nil
}

func (b *FragmentIteratorBuilder) nextFragment() {
	b.Reset()
	var its = b.its[:0]
	for _, it := range b.its {
		if !it.NextFragment() {
			continue
		}

		its = append(its, it)
		b.Add(it.pk)
	}
	b.its = its
	sort.Sort(b)
}

func (b *FragmentIteratorBuilder) nextSegment() error {
	for _, it := range b.its {
		if it.RemainRecordRow() > 0 {
			continue
		}

		err := it.NextSegment()
		if err == io.EOF {
			continue
		}
		if err != nil {
			return err
		}
	}
	return nil
}

// FragmentIterator used for iterating data in Fragment
// constructed through FragmentIteratorBuilder
type FragmentIterator struct {
	colstore.OffsetKeySorter
	its             []*CSFileIterator
	skSchema        record.Schemas
	compactedSchema record.Schemas
}

func NewFragmentIterator(skSchema record.Schemas) *FragmentIterator {
	fi := &FragmentIterator{
		skSchema: skSchema,
	}
	fi.SetDesc(true)
	return fi
}

func (fi *FragmentIterator) Reset() {
	fi.its = fi.its[:0]
}

func (fi *FragmentIterator) AddCSFileIterator(it *CSFileIterator) {
	if it.RemainRecordRow() == 0 {
		return
	}

	idx := len(fi.its)
	fi.its = append(fi.its, it)
	fi.buildSortKey(it.SegmentRecord(), idx)
}

func (fi *FragmentIterator) BuildCompactedSchema(its []*CSFileIterator) {
	fields := map[string]uint8{}
	for _, it := range its {
		colMeta := it.cm.GetColMeta()
		for i := range colMeta {
			fields[colMeta[i].Name()] = colMeta[i].Type()
		}
	}

	for name, typ := range fields {
		fi.compactedSchema = append(fi.compactedSchema, record.Field{Type: int(typ), Name: name})
	}
	sort.Sort(record.CustomSchemas(fi.compactedSchema))
}

func (fi *FragmentIterator) AppendTo(dst *record.Record, batchSize int) error {
	if len(fi.Offsets) == 0 {
		return io.EOF
	}

	dst.ResetWithSchema(fi.compactedSchema)

	for batchSize > 0 && len(fi.Offsets) > 0 {
		i := len(fi.Offsets) - 1
		v := fi.Offsets[i]
		n := v >> 32
		it := fi.its[n]
		rowIdx := int(v & math.MaxUint32)

		fi.deleteLast()
		it.AppendRecordRowTo(dst, rowIdx)
		batchSize--

		if it.RemainRecordRow() > 0 {
			continue
		}

		err := it.NextSegment()
		if err == io.EOF {
			continue
		}
		if err != nil {
			return err
		}

		fi.buildSortKey(it.SegmentRecord(), int(n))
		sort.Sort(fi)
	}

	return nil
}

func (fi *FragmentIterator) deleteLast() {
	n := len(fi.Offsets) - 1
	fi.Offsets = fi.Offsets[:n]
	if len(fi.Keys) > 0 {
		fi.Keys = fi.Keys[:n]
	}
	if len(fi.Times) > 0 {
		fi.Times = fi.Times[:n]
	}
}

func (fi *FragmentIterator) buildSortKey(rec *record.Record, n int) {
	if colstore.OnlySortByTime(fi.skSchema) {
		times := rec.Times()
		for i := range rec.RowNums() {
			fi.Times = append(fi.Times, times[i])
			// The high 32 bits record the iterator sequence number, and the low 32 bits record the row number.
			fi.Offsets = append(fi.Offsets, int64(n<<32|i))
		}
		return
	}

	cols := record.FetchColVals(rec, fi.skSchema)
	var buf []byte
	for i := range rec.RowNums() {
		buf = colstore.FetchKeyAtRow(buf, cols, fi.skSchema, i, 0)
		fi.Add(buf)
		buf = buf[len(buf):]
		fi.Offsets = append(fi.Offsets, int64(n<<32|i))
	}
}

type CSConsumeIterator struct {
	its      []*CSFileIterator
	releases []func()
}

func NewCSConsumeIterator(its []*CSFileIterator) *CSConsumeIterator {
	itr := &CSConsumeIterator{
		its: its,
	}

	for _, it := range its {
		it.file.Ref()
		itr.releases = append(itr.releases, func() {
			it.file.Unref()
		})
	}

	return itr
}

func (csi *CSConsumeIterator) sort() {
	sort.Slice(csi.its, func(i, j int) bool {
		return bytes.Compare(csi.its[i].pk, csi.its[j].pk) <= 0
	})
}

func (csi *CSConsumeIterator) Release() {
	for _, fn := range csi.releases {
		fn()
	}
	clear(csi.releases)
	clear(csi.its)
}

func (csi *CSConsumeIterator) Next() (*record.ConsumeRecord, error) {
	for {
		if len(csi.its) == 0 {
			return nil, io.EOF
		}

		ci := csi.its[0]
		err := ci.NextSegment()
		if err == io.EOF {
			ok := ci.NextFragment()
			if !ok {
				// iteration completed
				csi.its = csi.its[1:]
				continue
			}
			csi.sort()
			continue
		}

		return csi.buildConsumeRecord(ci), nil
	}
}

func (csi *CSConsumeIterator) buildConsumeRecord(ci *CSFileIterator) *record.ConsumeRecord {
	rec := ci.ReadAll()
	cr := &record.ConsumeRecord{
		Rec: rec,
		PK:  ci.ReadFragmentPK(),
	}

	return cr
}
